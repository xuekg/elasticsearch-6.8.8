[float]
[[breaking_60_analysis_changes]]
=== Analysis changes

[float]
==== Synonym Token Filter

In 6.0, Synonym Token Filter tokenizes synonyms with whatever
tokenizer and token filters appear before it in the chain.

The `tokenizer` and `ignore_case` parameters are deprecated
and will be ignored when used in new indices.  These parameters
will continue to function as before when used in indices
created in 5.x.

[float]
==== Limiting the length of an analyzed text during highlighting

Highlighting a text that was indexed without offsets or term vectors,
requires analysis of this text in memory real time during the search request.
For large texts this analysis may take substantial amount of time and memory.
To protect against this, the maximum number of characters that to be analyzed will be
limited to 1000000 in the next major Elastic version. For this version, by default the limit
is not set. A deprecation warning will be issued when an analyzed text exceeds 1000000.
 The limit can be set for a particular index with the index setting
`index.highlight.max_analyzed_offset`.

[float]
[[_literal_standard_literal_filter_has_been_deprecated]]
==== `standard` filter has been deprecated
 The `standard` token filter has been deprecated because it doesn't change anything in
 the stream. It will be removed in the next major version.

[float]
==== Deprecated standard_html_strip analyzer

The `standard_html_strip` analyzer has been deprecated, and should be replaced
with a combination of the `standard` tokenizer and `html_strip` char_filter.
Indexes created using this analyzer will still be readable in elasticsearch 7.0,
but it will not be possible to create new indexes using it.